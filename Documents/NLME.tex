\documentclass[12pt]{extarticle}
\usepackage[top=0.5in, bottom=0.8in, left=0.5in, right=0.5in]{geometry}

\usepackage{amsmath,amssymb,amsfonts,amsthm}            
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
\usepackage{bm}
\usepackage{verbatim}
\usepackage[all]{xy}
\usepackage[pdftex]{hyperref}
\usepackage{multirow}
\hypersetup{colorlinks=false, linkcolor=blue, pdffitwindow=true, pdftitle={mixed_effects_model}}

\title{Review of Nonlinear Mixed Effects Model}

\begin{document}
\maketitle
\begin{abstract}
This is a basic review of the nonlinear mixed effects (NLME) model which need to be improved and expanded in the future. NLME models are very useful in describing some dynamic system with measurements of individuals from population. This paper introduces some methods very briefly and observes some application of NLME model.
\end{abstract}
\section{Introduction of NLME}
\label{sect:Introduction}
In some research, the dataset may come from frequent measurements from samples of individuals from a population. For example, blood samples collected from several subjects in pharmacokinetic analysis and HIV dynamic research, milk samples collected from dairy cattles in dairy science, permanent sample plots in forestry, etc. It is a challenge to make inference from dataset like this. There are some common properties in population and some special properties in individuals so some mixed effects model will be a good solution. The first candidate may be linear mixed effects model but it is too simple to describe dynamic system. So nonliear mixed effects models have become a popular platform for alalysis of these datasets.

\subsection{Basic Model}
\label{sect:basic}
According to \cite{Davidian03}, the basic nonlinear mixed effects model has two stages, individual model and population model.

\begin{align}
Stage 1: \ Individual\  Model. & & y_{ij} = f(x_{ij},\beta_{i})+e_{ij}, & & j=1,\ldots,n_{i} \label{im1} \\
Stage 2: \ Population\  Model.  & & \beta{i} = d(a_{i},\beta,b_{i}), & & i=1,\ldots,m \label{pm1} 
\end{align}

where $x_{ij}$ can be time or response of the system, $y_{ij}$ denotes the $j$th measurement of the response, $\beta_{i}$ denotes the parameters, $e_{ij}$ denotes the realization error and measurement error, $a_{i}$ can be some fixed sysematic properties, $\beta$ denotes the fixed parameters (effects) in population and $b_{i}$ denotes the random effects. What is more, there is a parameter $u_i$ denotes the initial status, such as the dose at time zero in pharmacokinetic analysis.

The two stages of this model are both nonlinear. In practice, the second stage \eqref{pm1} is often simplified to linear form as:
\begin{equation}
\beta{i}=A_{i}\beta+B_{i}b_{i}, \label{pm2} 
\end{equation}

\section{Inference of NLME Model}
\label{sect:infer}
There are a number of inferential methods for NLME.  Most of these methods are based on likelihood or Bayesian method.

\subsection{Methods Based on Individual Estimates} 
\label{sect:ie}
If the number of (measurement) samples is sufficiently large and the estimators of parameter $\beta{i}$ are asymptotically normal, then the methods based on individual estimates can be used. The first step of these methods is to estimate the parameters $\beta{i}$ from individual model. Then fit some linear mixed effects model based on the linear form population model \eqref{pm2} with known "error" covariance matrix. EM algorithm or other techniques can be applied to this step.

\subsection{Methods Based on  Likelihood}
\label{sect:likelihood}
When the number of (measurement) samples is not large enough, we can not get good estimators of  $\beta{i}$ from individual model. So other methods based on likelihood have been developed. The difficulty is that integrations appear in the likelihood function of NLME model. So in the beginning, first order methods and first order conditional methods are developed to get acceptable estimates based on approximation of the likelihood. With the advances in computational power, some new methods can be used to handle the integral using deterministic or stochastic approximation. EM-algorithm is also used to maximize the likelihood function where "E-step" is carried out using Monte Carlo integration.

\subsection{Methods Based on a Bayesian Formulation}
\label{sect:bayesian}

Bayesian analysis with MCMC techniques is a natural powerful weapon for NLME model. The detail of this approach is in~\ref{sect:bayesianapproach} as an specific example.  \footnote{The content of~\ref{sect:Introduction} and ~\ref{sect:infer} comes from \cite{Davidian03}.}

\section{Some Applications}
\label{sect:application}

\subsection{Dynamic Gene Regulatory Network Identification}
\label{sect:network}
There are two major challenges in dynamic gene regulatory network identification, one is the high dinemsional system, the other one is the construction of dynamic network. \cite{Lu11}  applies ODE model for gene regulatory network (GRN) and proposes a five steps procedure CSIEF to identify dynamic GRNs, which includes clustering step, smoothing step, regulation identification step, parameter estimates refining step and function enrichment analysis step.

In these five steps, the clustering step and smoothing step use mixed effects model, the NLME model is involved in the parameter estimates refining step. The brief introduction of each step is given below.

\paragraph{Step 1: Clustering}
The purpose of this step is to reduce the dimension of the model. In the mean time, the problem is changed from 'gene regulatory network' to 'functional module regulatory network' based on the assumption that genes with similar function will not affect each other.

The approach as following is from  \cite{Ma08}.

Denote $G_i={(g_{i}(t_{1}),\ldots,g_{i}(t_{n_i}))}^T$ as the expression data vector for the $i$th gene, assume $G_i$ follows mixture normal distribution with $p$ clusters,
\begin{equation}
G_{i}\sim{}\sum_{k=1}^{p}w_{k}N(\mu_{k}(T_{i}),\Sigma_{k}), i=1,\ldots,n,
\end{equation}
The measurement model for $G_i$ for the $k$th cluster is
\begin{equation}
G_i=mu_{k}(T_{i})+Z_{i}b_{i}+\epsilon_{i},
\end{equation}
The maximum penalized likelihood approach and the EM algorithm can both be used to estimate the parameters in the models. BIC criterion can be used to determine the number of clusters.
\paragraph{Step 2: Smoothing}
This step will estimate the mean curve and its derivative for each module independently, the NPME model is as following \cite{Wu02}
\begin{equation}
g_{ki}(t_{ij})=M_{k}(t_{ij})+V_{ij}(t_{ij})+\epsilon_{k}(t_{ij})
\end{equation}
where $M_{k}(t)$ is the mean expression curve for the $k$th module and $M_{k}^{'}(t)=dM_{k}(t)/dt$ denotes its derivate. There are many methods can be used to estimate $M_{k}(t)$ and $M_{k}^{'}(t)$, a good reference is \cite{Wu06}.
\paragraph{Step 3: regulation Identification}
The ODE model in this step is as following
\begin{equation}
y_{k}(t)=\sum_{j=1}^{p}\beta_{kj}x_{j}(t)+\varepsilon_{k}(t),
\end{equation}
where $y_{k}(t)=\hat{M}_{k}^{'}(t)$ and $x_{j}(t)=\hat{M}_{j}(t)$.
There are two targets in this step, the primary one is model selection, the secondary one is to estimate parameters (of the system) for the first time. There are many method for this purpose to the standard high-dimensional linear regression model such as stepwise, bridge selection, LASSO, LARS, and so on. Here a method named CCCP-SCAD is used, which is the combination of concave convex procedure (CCCP) \cite{Le97} and smoothly clipped absolute deviation (SCAD) \cite{Fan01}, the detail of this part is from \cite{Kim08}.
\paragraph{Step 4: parameter Estimates refining}
The estimation in step 3 is computationally efficient and easy to implement. But this estimation is not very efficient in terms of estimation accuracy. So a NLME modeling approach is used to improve the accuracy.
The mixed-effects ODE model for module $k$ is
\begin{equation}
\frac{dx_{ki}}{dt}=\sum_{j=1}^{m_k}\beta_{kij}M_{[kj]}(t), i=1,\ldots,n_k; k=1,\ldots,p. \label{s41}
\end{equation}
where $x_{ki}$ is the gene exression level the the $i$th gene in the $k$th module, $n_k$ is the number of genes in the $k$th module, $M_{[kj]}(t)$ are mean expression levels of the modules that have nonzero coefficients determined by SCAD on the $k$th module, $m_k$ is the number modules that have nonzero coefficients on the $k$th module.

The SAEM approach \cite{Delyon99} is used to fit the model \eqref{s41}.
\paragraph{Step 5: Function enrichment analysis}
This step only build the GRN according to the estimation from the previous steps.

The five steps procedure overcomes the two major challenge successfully, but the correctness of the result is based on a strong assumption that the clustering is correct and the genes in a module do not affect each other. What is more, there are two steps have relationship with model selection which is a great risk to the correctness of the result.

\subsection{Pharmacokinetic}
\label{sect:pharmacokinetic}
The main purpose of a clinical pharmacokinetic (PK) study is to understand the pharmacokinetics of a drug \cite{Li02}. There are one-compartment models and two-conpartment models in pharmacokinetic study. Two-compartment models consider the amount of drug in the gut, blood and tissue. Let $A_{1,i}(t)$, $A_{2,i}(t)$, $A_{3,i}(t)$ represent the amounts of drugs in gut, blood and tissue at time $t$ respectively, with initial value to be $1$, $0$, $0$ respectively which is to say that all the drug is in gut at time $0$. Let $k_{a,i}$ denote the absorption rate, $k_{e,i}$ denote the elimination rate (for subject $i$). What is more, $k_{23,i}$ and $k_{32,i}$ are the distribution rates for subject $i$. Then the two-compartment model is
\begin{equation}
\begin{array}{rcl}
\frac{dA_{1,i}(t)}{dt} & = & -k_{a,i}A_{1,i}(t), \\
\frac{dA_{2,i}(t)}{dt} & = & k_{a,i}A_{1,i}(t) - (k_{e,i}+k_{23,i})A_{2,i}(t)+k_{32,i}A_{3,i}(t), \\
\frac{dA_{3,i}(t)}{dt} & = & k_{23,i}A_{2,i}(t)-k_{32,i}A_{3,i}(t).
\end{array}
\end{equation}
Let $k_{23,i}=0$ and $k_{32,i}=0$ then this model is simplified to one-compartment model. 

One of the drawback of these models is that the rates are constant over time which can not discribe some real situation. According to \cite{Li02}, the two-conpartment model with time-varying rates has some identifiable problem. So as an alternative, a one-conpartment model with time-varying rates is considered. Let us begin with the basic time-dependent PK model as following.
\begin{equation}
\begin{array}{rcl}
\frac{dA_{1,i}(t)}{dt} & = & -k_{a,i}(t)A_{1,i}(t), \\
\frac{dA_{2,i}(t)}{dt} & = & k_{a,i}(t)A_{1,i}(t) - k_{d,i}(t)A_{2,i}(t)
\end{array}
\end{equation}
where $k_{a,i}(t)$ is an absorption process function and $k_{d,i}(t)$ is a disposition process function (for subject $i$). We can see that the disposition process function replaces elimination rate because the disposition process includes the elimination process. 

The measurement error of the drug concentration often has a constant coefficient of variation so a log transformation can make the variance homogeneous. What is more, the functions  $k_{a,i}(t)$ and $k_{d,i}(t)$  are too general to use in practice, so $k_{a,i}(t)$ is modeled by a step function and $k_{d,i}(t)$ is modeled by a natural cubic spline function. This is the SEPK model (spline enhanced pharmacokinetic model). 
\begin{equation}
\begin{array}{rcl}
y_{ij} & = & f\{k_{a,i}(t_{ij}),k_{d,i}(t_{ij}),V_{i},t_{ij}\}+\epsilon_{ij}, \\
log(V_{i}) & = & X_{1,i}a_{1}+Z_{1,i}b_{1i}, \\
log(k_{a,i}(t_{ij})) & = & X_{2,ij}a_{2}+Z_{2,ij}b_{2i}, \\
log(k_{d,i}(t_{ij})) & = & X_{3,ij}a_{3}+g(t_{ij})+Z_{3,ij}b_{3i}, 
\end{array}
\end{equation}
where $y_{ij}$ is the observed log plasma drug concentration for subject $i$ at time $t_{ij}$, $V_{i}$ is the subject-specific volume of distribution and the true plasma drug concentration is $A_{2,i}(t)/V_{i}$. The function $f(\cdot)$ is log transformation of the true plasma drug concentration. $X_{ij}=diag(X_{1,i},X_{2,ij},X_{3,ij})$ is a $3\times{}p$-dimensional time-dependent design matrix for the $p$-dimensional fixed effect vector $a=(a_{1}^{T},a_{2}^{T},a_{3}^{T})^{T}$, $Z_{ij}=diag(Z_{1,i},Z_{2,ij},Z_{3,ij})$ is a  $3\times{}q_{i}$-dimensional time-dependent design matrix for the $q_{i}$-dimensional random effect vector $b_{i}=(b_{1i}^{T},b_{2i}^{T},b_{3i}^{T})^{T}$, $\epsilon_{ij}$ is i.i.d. $N(0,\sigma_{0}^{2})$, $b_{i}$ is i.i.d. $N(0,D_{i})$ and $g(t)$ is spline function. The individual and populaton model can be written as
\begin{equation}
\begin{array}{rcl}
Y & = & f\{\beta(t),t\}+\epsilon, \\
log\{\beta(t)\} & = & Xa+Ng+Zb,
\end{array}
\end{equation} 
where $\beta(t)$ denotes $V_{i},k_{a,i}(t_{ij}),k_{d,i}(t_{ij})$ for all the subject i, $N$ denote the indicator matrix for spline function $g$. The parameters of the model and the spline function can be estimated by approximation maximum likelihood approach mentioned in~\ref{sect:likelihood}. 
\subsection{HIV Dynamic Models}
\label{sect:hiv}
The basic HIV dynamic model is a model that describes the population dynamics of HIV and its target cells in plasma.
\begin{equation}
\begin{array}{rcl}
\frac{dT}{dt} & = & \lambda{}-\rho{}T-kTV \\
\frac{dT^{*}}{dt} & = & kTV-\delta{}T^{*} \\
\frac{dV}{dt} & = & N\delta{}T^{*}-cV
\end{array}
\end{equation}
where $T$, $T^{*}$ and $V$ are target uninfected CD4+ T cells, infected CD4+ T cells and virus, respectively.  $\rho$, $\delta$, $c$ are death rate of target uninfected CD4+ T cells, infected CD4+ T cells and virus, respectively. $\lambda$ represents the produce rate of new CD4+ T cells from body, k is the infected rate and N is the number of new virions produced from each (death) infected T cell.
The fundamental concept is basic reproductive ratio $R_{0}$ \cite{Putter02} which is given by
\begin{equation}
R_{0}=\frac{\lambda{}kN}{\rho{}c}
\end{equation}
When $R_{0}>1$, the system will reach some equilibrium status as following
\begin{equation}
\begin{array}{rcl}
T_{0} & = & \frac{c}{kN}, \\
V_{0} & = & \frac{\lambda{}N}{c}-\frac{\rho}{k}, \\
T_{0}^{*} & = & \frac{c}{\delta{}N}, 
\end{array}
\end{equation}
This is the initial values of all the HIV dynamic models with antiviral. Roughly speaking, there are two types of antiviral drugs which are commonly used in standard anti-HIV treatment \cite{Putter02}. The first is inhibitors of Reverse Transcriptase (RTI's), the second is protease inhibitors (PI's). The RTI's inhibit the transcription of viral RNA into DNA which will prevent the CD4+ T cells being infected. The PI's inhibit the cleaving of long multi-proteins into smaller functional units to render a large fraction of virus particles defactive. Then we can conclude the general post-treatment system of differential euqtions:
\begin{equation}
\begin{array}{rcl}
\frac{dT}{dt} & = & \lambda{}-\rho{}T-(1-\eta{}_{RTI}(t))kTV \\
\frac{dT^{*}}{dt} & = & (1-\eta{}_{RTI}(t))kTV-\delta{}T^{*} \\
\frac{dV}{dt} & = & (1-\eta{}_{PI}(t))N\delta{}T^{*}-cV \\
\frac{dU}{dt} & = & \eta{}_{PI}(t)N\delta{}T^{*}-cU \label{generalmodel}
\end{array}
\end{equation}
where $\eta{}_{RTI}(t)$ indicates the fraction of new infections inhibited, $\eta{}_{PI}(t)$ denotes the fraction of virus produced being non-infectious. Both of them take value from $0$ to $1$, $0$ means no treatment and $1$ means perfect inhibition. $V$ and $U$ denote the infectious virus and defective virus respectively. The concept of this part comes from \cite{Putter02} and the notations follow \cite{Huang0601} in general.

To estimate parameters from these models, The first thing is to discuss the identifiability of the parameters. Basicly speaking, there always be some parameters which are not identifiable because there are too many parameters in the model. Then we have to take some of them as constant based on prior knowledge. The next step is to transform the remaining parameters to proper form (such as log form or some combination) and then take them into a NLME model. Finally, we can get the estimation of them by maximum likelihood approach or Bayesian approach.
\subsubsection{Likelihood Approach}
\label{sect:likelihoodapproach}
\cite{Guedj07} proposes a model which is some different from the general model \eqref{generalmodel}.
\begin{equation}
\left\{
\begin{array}{rcl}
\frac{dQ}{dt} & = & \lambda{}+\alpha{}_{T}T-\alpha{}_{Q}Q-\mu{}Q \\
\frac{dT}{dt} & = & \alpha{}_{Q}Q-(1-\eta{}_{RTI}(t))kTV-\rho{}T-\alpha{}_{T}T \\
\frac{dT^{*}}{dt} & = & (1-\eta{}_{RTI}(t))kTV-\delta{}T^{*} \\
\frac{dV}{dt} & = & (1-\eta{}_{PI}(t))N\delta{}T^{*}-cV \\
\frac{dU}{dt} & = & \eta{}_{PI}(t)N\delta{}T^{*}-cU
\end{array}
\right.
\end{equation}
whrere $Q$ is quiescent CD4+ T cells, $\mu{}$ is death rate of it, $\alpha{}_Q$ is the transform rate from $Q$ to $T$ and $\alpha{}_T$ is the transform rate from $T$ to $Q$.
A maximum likelihood appoach is used in \cite{Guedj07}. Because the model is some complex, not the log likelihood function but the first derivatives of it are used to estimate the parameters. 
\subsubsection{Bayesian Approach}
\label{sect:bayesianapproach}
Another way is the Bayesian approach. Many specific models have been established. \cite{Putter02} proposed a short term model in which the efficiency of RTI and PI is considered to be constant and equal. \cite{Huang0601} and \cite{Huang0602} proposed a simplified model in which only the RTI drugs involved and used $IC_{50}$ to model the drug efficiency. The process of these models are very similar so we take \cite{Huang0601} as example.

$IC_{50}$ represents the drug concentration necessary to inhibit viral replication by $50\%$. Then the drug efficiency is represented as
\begin{equation}
\gamma{}(t)=\frac{C_{min}A(t)}{\phi{}IC_{50}(t)+C_{min}A(t)}=\frac{IQ(t)A(t)}{\phi{}+IQ(t)A(t)}
\end{equation}
where $C_{min}$ is the minimum concentration of drug in plasma and $IQ(t)=C_{min}/IC_{50}(t)$ denotes  the inhibitory quotient (IQ). $A(t)$ is indicator of doses to patients, $\phi$ indicates a conversion factor. With this function $\gamma{}(t)$ the model will become
\begin{equation}
\begin{array}{rcl}
\frac{dT}{dt} & = & \lambda{}-\rho{}T-(1-\gamma{}(t))kTV \\
\frac{dT^{*}}{dt} & = & (1-\gamma{}(t))kTV-\delta{}T^{*} \\
\frac{dV}{dt} & = & N\delta{}T^{*}-cV  \label{specificmodel}
\end{array}
\end{equation}
There are too many parameters so the prior information must be used to avoid the identifiability problem. After this step, the remaining parameters must be transformed for convenience. Denote the number of subjects by $n$ and the number of measurements on the $i$th subject by $m_i$, let
\begin{equation}
\begin{array}{rcl}
\mu & = & (log\phi{},logc,log\delta{},log\lambda{},log\rho{},logN,logk)^{T}, \\
\Theta & = & \{\theta_{i},i=1,\ldots,n\}, \\
\theta_{i} & = & (log\phi{}_{i},logc_{i},log\delta{}_{i},log\lambda{}_{i},log\rho{}_{i},logN_{i},logk_{i})^{T}, \\
\Theta_{\{i\}} & = & \{\theta_{l},l\neq{}i\}, \\
Y & = & \{y_{ij},i=1,\ldots,n;j=1,\ldots,m_{i}\}
\end{array}
\end{equation}
Let $f_{ij}(\theta_{i},t_{j})$ be logarithm of the (numeric) solution of $V$ from \eqref{specificmodel} for the $i$th subject at time $t_j$. The repeated measurements of it, $y_{ij}(t)$ can be written as
\begin{equation}
y_{ij}(t_{j})=f_{ij}(\theta_{i},t_{j})+e_{i}(t_{j}), i=1,\ldots,n;j=1,\ldots,m_{i}
\end{equation}
where $e_{i}(t)$ is a measurement error with mean zero. Then a Bayesian nonlinear mixed-effect model can be written as following stages.

\paragraph{Stage 1.}
Within-subject variation in common logarithmic viral load measurements which is the individual model:
\begin{equation}
y_{i}=f_{i}(\theta{}_{i})+e_{i}, [e_{i}|\sigma{}^{2},\theta{}_{i}]\sim{}N(0,\sigma{}^{2}I_{m_i})
\end{equation}
\paragraph{Stage 2.}
Between-subject variation which is the population model:
\begin{equation}
\theta_{i}=\mu+b_{i}, [b_{i}|\Sigma]\sim{}N(0,\Sigma)
\end{equation}
\paragraph{Stage 3.}
Hyperprior distribution:
\begin{equation}
\sigma^{-2}\sim{}Ga(a,b), \mu\sim{}N(\eta,\Lambda), \Sigma{}^{-1}\sim{}Wi(\Omega,v)
\end{equation}
The parameters in the hyperprior distribution are known. Then the iterative MCMC algorithm can be outlined as follows

\paragraph{Step 1.}
Initialize the iteration counter to $j=1$ and start with initial values $\Gamma{}^{(0)}=(\sigma{}^{-2(0)},\mu{}^{(0)},\Sigma{}^{-1(0)},\Theta{}^{(0)})^{T}$.
\paragraph{Step 2.}
Obtain a new value  $\Gamma{}^{(j)}=(\sigma{}^{-2(j)},\mu{}^{(j)},\Sigma{}^{-1(j)},\Theta{}^{(j)})^{T}$ from $\Gamma{}^{(j-1)}$ through successive generation of values:
\paragraph{Step 2.1 Gibbs sampling.}
\begin{equation}
\begin{array}{rcl}
\sigma{}^{-2(j)} & \sim{} & \pi{}(\sigma^{-2}|\mu{}^{(j-1)},\Sigma{}^{-1(j-1)},\Theta{}^{(j-1)},Y) \\
\mu{}^{(j)} & \sim{} & \pi{}(\mu{}|\sigma{}^{-2(j-1)},\Sigma{}^{-1(j-1)},\Theta{}^{(j-1)},Y) \\
\Sigma{}^{-1(j)} & \sim{} & \pi{}(\Sigma{}^{-1}|\sigma{}^{-2(j-1)},\mu{}^{(j-1)},\Theta{}^{(j-1)},Y)
\end{array}
\end{equation}
\paragraph{Step 2.2 Metropolis-Hastings step.}
For $\theta{}_{i}^{(j)}$, generate a new value $\varphi$ from the proposal (symmetric) density $q(\varphi{}|\theta{}_{i}^{(j-1)})$, calculate
\begin{equation}
\alpha{}(\varphi{}|\theta{}_{i}^{(j-1)})=\frac{\pi{}(\varphi{}|\sigma{}^{-2(j)},\mu{}^{(j)},\Sigma{}^{-1(j)},\Theta{}_{\{i\}}^{(j-1)},Y)}{\pi{}(\theta{}_{i}^{(j-1)}|\sigma{}^{-2(j)},\mu{}^{(j)},\Sigma{}^{-1(j)},\Theta{}_{\{i\}}^{(j-1)},Y)}
\end{equation}
If $\alpha{}(\varphi{}|\theta{}_{i}^{(j-1)})\ge{}1$ then accept it,$\theta{}_{i}^{(j)}=\varphi{}$. If $\alpha{}(\varphi{}|\theta{}_{i}^{(j-1)})<1$ then also accept it with a given probability.
\paragraph{Step 3.}
Change the counter from $j$ to $j+1$ and return to Step 2 until convergence is reached.

\section{Conclusion}
In this paper, we introduce the concept of NLME models and list some applications of this kind of model. The parameter estimating methods have some advantage and drawback respectively and there is not a uniform algorithm to solve the problem. Some applications have potential to improve. For example the pharmacokinetic model may be can used in the HIV dynamic model to character the efficiency of drugs.

\begin{thebibliography}{9}

\bibitem{Le97}
Le Thi Hoai A, Tao P D., 
\emph{Solving a class of linearly constrained indefinite quadratic problems by DC algorithms.} 
Journal of Global Optimization, 1997, 11(3): 253-285.

\bibitem{Delyon99}
Delyon B, Lavielle M, Moulines E., 
\emph{Convergence of a stochastic approximation version of the EM algorithm.} 
Annals of statistics, 1999: 94-128.

\bibitem{Fan01}
Fan J, Li R.,
\emph{Variable selection via nonconcave penalized likelihood and its oracle properties.} 
Journal of the American statistical Association, 2001, 96(456): 1348-1360.

\bibitem{Putter02}
Putter, H., et al., 
\emph{A Bayesian approach to parameter estimation in HIV}. 
dynamical models. Stat Med, 2002. 21(15): p. 2199-214.

\bibitem{Li02}
Li, L., et al., 
\emph{Estimation and inference for a spline-enhanced population pharmacokinetic model}. 
Biometrics, 2002. 58(3): p. 601-11.

\bibitem{Wu02}
Wu H, Zhang J T., 
\emph{Local polynomial mixed-effects models for longitudinal data}. 
Journal of the American Statistical Association, 2002, 97(459): 883-897.

\bibitem{Davidian03}
Davidian M, Giltinan D M, 
\emph{Nonlinear models for repeated measurement data: an overview and update}. 
Journal of Agricultural, Biological, and Environmental Statistics, 2003, 8(4): 387-419.

\bibitem{Huang0601}
Huang, Y. and H. Wu, 
\emph{A bayesian approach for estimating antiviral efficacy in HIV dynamic models}. 
J Applied Statistics, 2006. 33: p. 155-174.

\bibitem{Huang0602}
Huang, Y., Liu, D. and Wu, H., 
\emph{Hierarchical Bayesian Methods for Estimation of Parameters in a Longitudinal HIV Dynamic System}. 
Biometrics, 2006. 62, 413-423

\bibitem{Wu06}
Wu H, Zhang J T., 
\emph{Nonparametric regression methods for longitudinal data analysis: mixed-effects modeling approaches.} 
John Wiley \& Sons, 2006.

\bibitem{Guedj07}
Guedj, J., R. Thiebaut, and D. Commenges, 
\emph{Maximum likelihood estimation in dynamical models of HIV.} 
Biometrics, 2007. 63(4): p. 1198-206.

\bibitem{Ma08}
Ma P, Zhong W., 
\emph{Penalized clustering of large-scale functional data with multiple covariates.} 
Journal of the American Statistical Association, 2008, 103(482).

\bibitem{Kim08}
Kim Y, Choi H, Oh H S., 
\emph{Smoothly clipped absolute deviation on high dimensions.} 
Journal of the American Statistical Association, 2008, 103(484): 1665-1673.

\bibitem{Lu11}
Lu, T., Liang, H., Li, H., Wu, H., 
\emph{High Dimensional ODEs Coupled with Mixed-Effects Modeling Techniques for Dynamic Gene Regulatory Network Identification}. 
Journal of the American Statistical Association, 2011. 106, 1242-1258.

\end{thebibliography}

\end{document}
